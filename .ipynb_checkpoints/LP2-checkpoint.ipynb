{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementos de un lenguaje de programación\n",
    "\n",
    "Léxico: conjunto de símbolos base y cómo formar las palabras del lenguaje\n",
    "\n",
    "Sintaxis: conjunto de reglas para combinar las palabras en frases o expresiones correctas\n",
    "\n",
    "Semántica: conjunto de reglas para determinar si una frase o conjunto de frases del lenguaje es correcta respecto a su significado, no su estructura. Ejemplo: sistema de tipos del lenguaje\n",
    "\n",
    "*Implementación\n",
    "\n",
    "Oferta: si quieren ahondar en su conocimiento en Python, hay un Humble Bundle de puro Python: \n",
    "https://www.humblebundle.com/books/python-programming-no-starch-books\n",
    "\n",
    "Oferta de tiempo limitado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Léxico\n",
    "\n",
    "Conjunto L de palabras (tokens) con las que se construyen expresiones.\n",
    "\n",
    "L es a su vez un subconjunto de A*, donde A es el alfabeto de símbolos atómicos del que se conforman las palabras del lenguaje (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hhh\n",
      "hhe\n",
      "heeh\n",
      "eeh\n",
      "h\n",
      "hee\n",
      "ehhe\n",
      "heee\n",
      "eheh\n",
      "eeeh\n",
      "hehe\n",
      "hehh\n",
      "ehe\n",
      "eehe\n",
      "ehh\n",
      "he\n",
      "eh\n",
      "ee\n",
      "hhhh\n",
      "eeee\n",
      "eee\n",
      "hhhe\n",
      "e\n",
      "hh\n",
      "heh\n",
      "eehh\n",
      "ehhh\n",
      "hhee\n",
      "hheh\n",
      "ehee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "A = {'h', 'e'}\n",
    "A3 = set(product(A, repeat=4)) | set(product(A, repeat=3)) | set(product(A, repeat=2)) | set(product(A, repeat=1))\n",
    "\n",
    "for tup in A3:\n",
    "    print(''.join(tup))\n",
    "    \n",
    "#W3 = map(lambda tup: ''.join(tup), A3)\n",
    "W3 = [''.join(tup) for tup in A3]\n",
    "    \n",
    "L = {'he', 'hehe'}\n",
    "\n",
    "L.issubset(W3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos de palabras, tokens, lexemas en un lenguaje de programación:\n",
    "\n",
    "Palabras reservadas (for, while, if, def)\n",
    "\n",
    "Identificadores\n",
    "\n",
    "Constantes o literales (enteros, flotantes, cadenas)\n",
    "\n",
    "Símbolos especiales (espacios en blanco, operadores, delimitadores como paréntesis o corchetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1.3', '1.5', '8']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isso(arr):\n",
    "    for i in range(len(arr)):\n",
    "        cursor = arr[i]\n",
    "        pos = i\n",
    "        \n",
    "        while pos > 0 and arr[pos - 1] > cursor:\n",
    "            arr[pos] = arr[pos - 1]\n",
    "            pos = pos - 1\n",
    "        arr[pos] = cursor\n",
    "        \n",
    "    return arr\n",
    "\n",
    "isso(['1.3', '1.5', '0', '8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una definición formal de lenguaje con base en su léxico\n",
    "\n",
    "Si tenemos un alfabeto A con todos los símbolos que pueden encontrarse en el lenguaje:\n",
    "\n",
    "A = {a-Z | 0-9 | +-*/% | ...}\n",
    "\n",
    "Entonces A* es el conjunto de todas las palabras que pueden formarse con esos símbolos\n",
    "\n",
    "Sea s una cadena de caracteres que representa un PROGRAMA entero, no solamente una palabra. Por tanto, podemos formalizar la definición de lenguaje a un conjunto de candenas C de todos los posibles programas escritos a partir de A, subconjunto también de A*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "#A_str = ' !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~'\n",
    "A_str = ' 012345+'\n",
    "A = set(A_str)\n",
    "\n",
    "PROGRAMA_1 = '2 + 3'\n",
    "PROGRAMA_2 = '5+++5'\n",
    "PROGRAMA_3 = '++0++'\n",
    "\n",
    "#M = list(reduce(lambda x,y: set(x) | set(y), list(map(lambda arity: set(product(A, repeat=arity)), list(range(20))))))\n",
    "\n",
    "A5 = set(product(A, repeat=5))\n",
    "P5 = [''.join(tup) for tup in A5]\n",
    "\n",
    "print(PROGRAMA_1 in P5)\n",
    "print(PROGRAMA_2 in P5)\n",
    "print(PROGRAMA_3 in P5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque hemos llegado a una definición formal de lenguaje con base en el conjunto alfabeto:\n",
    "\n",
    "L.issubset(A*)\n",
    "\n",
    "Esta definición no es muy útil, pues no me dicen cómo formar todas las cadenas s que pertenecen a L y que son correctas. \n",
    "\n",
    "Hace falta la sintaxis y semántica como mecanismos de construcción del conjunto completo y correcto de cadenas s de L, correspondiente a todos los posibles programas que puedo formar en el lenguaje L. \n",
    "\n",
    "Antes de adentrarnos en los otros elementos de un lenguaje de programación, es importante listar las herramientas que tengo para definir el léxico de un lenguaje: \n",
    "\n",
    "Conjuntos, con los que hemos trabajado hasta este momento.\n",
    "\n",
    "Autómatas de estados finitos: tal como se vieron en el curso de matemáticas computacionales. Nota: breve recordatorio en el pizarrón.\n",
    "\n",
    "Expresiones regulares: hagamos un ejemplo!\n",
    "\n",
    "Retomemos el último programa de Python y lo caro que resulta computacionalmente calcular el conjunto total de posibles programas o cadenas en general a partir de un alfabeto extenso. \n",
    "\n",
    "¿Cómo lo haríamos con expresiones regulares?\n",
    "\n",
    "AVISO: las expresiones regulares son voraces por definición.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "PROGRAMA_1 = '2 + 3'\n",
    "PROGRAMA_2 = '5+++5'\n",
    "PROGRAMA_3 = '++0++'\n",
    "\n",
    "PROGRAMA_4 = 'print(\"Hello World!\")'\n",
    "PROGRAMA_5 = 'def isso(arr):\\\n",
    "    for i in range(len(arr)):\\\n",
    "        cursor = arr[i]\\\n",
    "        pos = i\\\n",
    "        \\\n",
    "        while pos > 0 and arr[pos - 1] > cursor:\\\n",
    "            arr[pos] = arr[pos - 1]\\\n",
    "            pos = pos - 1\\\n",
    "        arr[pos] = cursor\\\n",
    "        \\\n",
    "    return arr'\n",
    "\n",
    "lenguaje = re.compile('^[\\s!\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~]*$')\n",
    "\n",
    "print(lenguaje.search(PROGRAMA_1) is not None)\n",
    "print(lenguaje.search(PROGRAMA_2) is not None)\n",
    "print(lenguaje.search(PROGRAMA_3) is not None)\n",
    "print(lenguaje.search(PROGRAMA_4) is not None)\n",
    "print(lenguaje.search(PROGRAMA_5) is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que esta definición es laxa y limitada para nuestro propósito: un plano de construcción y validación de un lenguaje de programación.\n",
    "\n",
    "Las herramientas que tenemos para la definición de léxico describen a su vez un lenguaje, pero del tipo regular, tales como: \n",
    "\n",
    "1. El lenguaje de palabras que comienza con a, seguido o no de una c y con una o más b\n",
    "2. El lenguaje de palabras que comienza con una letra o _, seguido cualquier número de de letras, números o _\n",
    "\n",
    "¿Cómo conocemos comúnmente al lenguaje regular descrito en el inciso 2?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos otra herramienta a nuestra disposición con la que podríamos definir el léxico de un lenguaje de programación: la gramática, que es un conjunto de derivaciones que sirven como plantilla para estructurar un lenguaje. \n",
    "\n",
    "Ejemplo: vamos a describir el lenguaje de los identificadores válidos de C++ con derivaciones o reglas de producción. *Usaremos una versión no estricta de EBNF para simplificar la escritura de la gramática*\n",
    "\n",
    "IDENT        -> IDENT_INICIO IDENT_RESTO+\n",
    "IDENT_INICIO -> _ | LETRA\n",
    "IDENT_RESTO  -> _ | LETRA | NUMERO\n",
    "\n",
    "Hay un problema con esta definición, respeto a las reglas de C++ para formar identificadores. ¿Lo ven? ¿Cómo lo arreglaríamos?\n",
    "\n",
    "A diferencias de las otras formas (conjuntos, autómatas de estados finitos o expresiones regulares), las gramáticas tienen un mayor poder expresivo, el cual permite definir todo el conjunto posible de lenguajes regulares, además de lenguajes libres de contexto. \n",
    "\n",
    "Ahora es un buen momento para revisar la jerarquía de lenguajes de Chomsky:\n",
    "\n",
    "https://www.google.com/url?sa=i&source=images&cd=&ved=2ahUKEwibhJLUh43kAhXKmq0KHQQqAgIQjRx6BAgBEAQ&url=https%3A%2F%2Fwww.geeksforgeeks.org%2Ftoc-chomsky-hierarchy%2F&psig=AOvVaw2MvOVs1G2xeN8CjwLGDRMq&ust=1566239688494529\n",
    "\n",
    "De menor a mayor en poder expresivo:\n",
    "\n",
    "Tipo 3 - Regular - Autómata de estados finitos\n",
    "Tipo 2 - Libre de contexto - Autómata de pila\n",
    "Tipo 1 - Sensitiva al contexto - Autómata acotado linealmente\n",
    "Tipo 0 - Recursivamente enumerable - Máquina de Turing\n",
    "\n",
    "En este curso sólo llegamos hasta el Tipo 2: gramáticas libres de contexto. Estas últimas nos ayudan a definir el siguiente elemento de un lenguaje: \n",
    "\n",
    "\n",
    "Sintaxis\n",
    "\n",
    "Hemos definido nuestro vocabulario gracias al conocimiento del análisis léxico, las herramientas y algunos ejemplos de código. Llegamos a una definición correcta, pero vaga, de lo que es un lenguaje, a partir de nuestro alfabeto. \n",
    "\n",
    "La sintaxis es el conjunto de reglas que nos ayuda a restringir las combinaciones de palabras de nuestro lenguaje en frases correctas. \n",
    "\n",
    "Asumamos que hemos alimentado a nuestro analizar léxico de una cadena de caracteres con nuestro programa:\n",
    "\n",
    "NOTA: instalen astdump\n",
    "\n",
    "pip3 install astdump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module\n",
      "  FunctionDef\n",
      "    arguments\n",
      "      arg\n",
      "    If\n",
      "      Compare\n",
      "        Name\n",
      "          Load\n",
      "        Eq\n",
      "        Num\n",
      "      Return\n",
      "        Num\n",
      "    If\n",
      "      Compare\n",
      "        Name\n",
      "          Load\n",
      "        Eq\n",
      "        Num\n",
      "      Return\n",
      "        Num\n",
      "      Return\n",
      "        BinOp\n",
      "          Call\n",
      "            Name\n",
      "              Load\n",
      "            BinOp\n",
      "              Name\n",
      "                Load\n",
      "              Sub\n",
      "              Num\n",
      "          Add\n",
      "          Call\n",
      "            Name\n",
      "              Load\n",
      "            BinOp\n",
      "              Name\n",
      "                Load\n",
      "              Sub\n",
      "              Num\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import astdump\n",
    "from pprint import pprint\n",
    "\n",
    "def fib(n):\n",
    "    if n==1:\n",
    "        return 0\n",
    "    if n==2:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "\n",
    "fib(10)\n",
    "\n",
    "fib_program = \"\"\"\n",
    "def fib(n):\n",
    "    if n==1:\n",
    "        return 0\n",
    "    if n==2:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "\"\"\"\n",
    "\n",
    "#tree = ast.parse(fib_program)\n",
    "\n",
    "astdump.indented(fib_program)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es árbol de tokens, también conocido como AST (Árbol de sintaxis abstracta).\n",
    "\n",
    "¿Por qué se representa con un árbol? ¿No bastaría una lista de tokens?\n",
    "\n",
    "¿Por qué no podemos usar una expresión regular o scanner para producir el mismo árbol de tokens que un parser libre de contexto?\n",
    "\n",
    "Un lenguaje regular no puede manejar definiciones recursivas. El ejemplo canónico que demuestra las limitaciones de un lenguaje regular es el siguiente: \n",
    "\n",
    "EXP -> ( EXP )\n",
    "EXP -> VACÍO\n",
    "\n",
    "Es el lenguaje que tienen la misma cantidad de paréntesis abiertos que cerrados, concordancia de paréntesis. \n",
    "\n",
    "Otro ejemplo más real: describir HTML con un lenguaje regular. \n",
    "\n",
    "Recordatorio de matemáticas computacionales: Lema del bombeo\n",
    "\n",
    "Otro forma intuitiva para determinar cuándo un lenguaje regular no es apto es cuando tenemos la necesidad de usar una pila (stack) para procesar la entrada y determinar que es correcta. Un stack, como en el caso de los autómatas de pila, nos permite recordar y añadir condiciones a las transiciones de un autómata de estados finitos. \n",
    "\n",
    "Ejemplo: \n",
    "\n",
    "L = {0^n1^n | n >= 0}\n",
    "\n",
    "El lenguaje que tiene la misma cantidad de 0s y 1s. Un lenguaje regular no puede recordar algo que haya procesado, y por tanto, tomar una decisión en esos términos. Va consumiendo la cadena de caracteres tal cual se le presenta, sin vuelta atrás. \n",
    "\n",
    "En cambio, un autómata de pila o gramática libre de contexto, tienen una notición de estado al usar una pila. En la gramática libre de contexto, el uso de la pila está implícito en su definición recursiva (callstack). \n",
    "\n",
    "Cada derivación es como si llamáramos una función, y necesitamos de una pila para llevar registro del anidamiento de llamadas a función. De esta analogía surge la primera estrategia que usaremos para implementar un analizar sintáctico: descendente recursivo.  \n",
    "\n",
    "Consideremos un lenguaje esotérico para hacer el ejemplo más ameno: \n",
    "http://www.lolcode.org/\n",
    "\n",
    "ejemplo de IF-THEN en lolcode:\n",
    "\n",
    "BOTH SAEM ANIMAL AN \"CAT\"\n",
    "O RLY?\n",
    "  YA RLY, VISIBLE \"J00 HAV A CAT\"\n",
    "  MEBBE BOTH SAEM ANIMAL AN \"MAUS\"\n",
    "    VISIBLE \"NOM NOM NOM. I EATED IT.\"\n",
    "OIC\n",
    "\n",
    "Python equivalente: \n",
    "\n",
    "```python\n",
    "if animal=='CAT':\n",
    "    print('J00 HAV A CAT')\n",
    "elif animal=='MAUS':\n",
    "    print('NOM NOM NOM. I EATED IT.'\n",
    "else:\n",
    "    print('HAZ ERRORZ')\n",
    "```\n",
    "\n",
    "Gramática:\n",
    "\n",
    "<code>\n",
    "EXPRESSION\n",
    "O RLY?\n",
    "  YA RLY\n",
    "    CODE_BLOCK\n",
    " [MEBBE EXPRESSION\n",
    "    CODE_BLOCK\n",
    " [MEBBE EXPRESSION\n",
    "    CODE_BLOCK\n",
    "  ...]]\n",
    " [NO WAI\n",
    "    CODE_BLOCK]\n",
    "OIC\n",
    "</code>        \n",
    "\n",
    "En EBNF:\n",
    "\n",
    "LOLCODE_IF_ELSE -> BOOLEAN ORLY YARLY CODE_BLOCK [{MEBBE BOOLEAN CODE_BLOCK}] [NOWAI CODE_BLOCK] OIC\n",
    "CODE_BLOCK -> LOLCODE_IF_ELSE | OTHER_STATEMENT\n",
    "\n",
    "Asumimos que ya nos entregan un stream de tokens como entrada:\n",
    "\n",
    "Ejemplo: \n",
    "\n",
    "token_stream = [ORLY, YARLY, ORLY, YARLY, CODE_BLOCK, OIC, OIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse_LOLCODE_IF_ELSE\n",
      "NEXT Token.BOOLEAN\n",
      "NEXT Token.ORLY\n",
      "NEXT Token.YARLY\n",
      "parse_LOLCODE_CODEBLOCK\n",
      "PEEK Token.OTHER_STATEMENT\n",
      "NEXT Token.OTHER_STATEMENT\n",
      "PEEK Token.NOWAI\n",
      "NEXT Token.NOWAI\n",
      "parse_LOLCODE_CODEBLOCK\n",
      "PEEK Token.OTHER_STATEMENT\n",
      "NEXT Token.OTHER_STATEMENT\n",
      "NEXT Token.OIC\n",
      "True\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Token(Enum):\n",
    "    BOOLEAN = 1\n",
    "    ORLY = 2\n",
    "    YARLY = 3\n",
    "    OTHER_STATEMENT = 4\n",
    "    MEBBE = 5\n",
    "    NOWAI = 6\n",
    "    OIC = 7\n",
    "    EOF = 8\n",
    "    \n",
    "def handle_parse_error(remaining_tokens):\n",
    "    print(f'ERROR DE SINTAXIS. FALTA POR PROCESAR: {remaining_tokens}')\n",
    "    \n",
    "def next_token(token_stream):\n",
    "    token = token_stream.pop(0) if token_stream else Token.EOF\n",
    "    print(f'NEXT {token}')\n",
    "    return token\n",
    "\n",
    "def peek_token(token_stream):\n",
    "    token = token_stream[0] if token_stream else Token.EOF\n",
    "    print(f'PEEK {token}')\n",
    "    return token   \n",
    "\n",
    "def parse_LOLCODE_CODEBLOCK(token_stream):\n",
    "    print('parse_LOLCODE_CODEBLOCK')\n",
    "    token = peek_token(token_stream)\n",
    "\n",
    "    if token == Token.BOOLEAN:\n",
    "        if not parse_LOLCODE_IF_ELSE(token_stream): return False\n",
    "    elif token != Token.OTHER_STATEMENT:\n",
    "        handle_parse_error(token_stream)\n",
    "        return False\n",
    "    else:\n",
    "        next_token(token_stream)\n",
    "    return True\n",
    "\n",
    "def parse_LOLCODE_MEBBE(token_stream):\n",
    "    print('parse_LOLCODE_MEBBE')\n",
    "    if next_token(token_stream) != Token.MEBBE:\n",
    "        handle_parse_error(token_stream)\n",
    "        return False\n",
    "    \n",
    "    if next_token(token_stream) != Token.BOOLEAN:\n",
    "        handle_parse_error(token_stream)\n",
    "        return False\n",
    "        \n",
    "    if not parse_LOLCODE_CODEBLOCK(token_stream): return False\n",
    "    \n",
    "    return True\n",
    "        \n",
    "def parse_LOLCODE_IF_ELSE(token_stream):\n",
    "    print('parse_LOLCODE_IF_ELSE')\n",
    "    if next_token(token_stream) != Token.BOOLEAN:\n",
    "        handle_parse_error(token_stream)\n",
    "        return False\n",
    "    elif next_token(token_stream) != Token.ORLY:\n",
    "        handle_parse_error(token_stream)\n",
    "        return False\n",
    "    elif next_token(token_stream) != Token.YARLY:\n",
    "        handle_parse_error(token_stream)\n",
    "        return False\n",
    "    else:\n",
    "        if not parse_LOLCODE_CODEBLOCK(token_stream): return False\n",
    "            \n",
    "        while(peek_token(token_stream) == Token.MEBBE):\n",
    "            if not parse_LOLCODE_MEBBE(token_stream): return False\n",
    "            \n",
    "        token = next_token(token_stream)\n",
    "        if(token == Token.NOWAI):\n",
    "            if not parse_LOLCODE_CODEBLOCK(token_stream): return False\n",
    "            \n",
    "        if(next_token(token_stream) != Token.OIC):\n",
    "            handle_parse_error(token_stream)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "    \n",
    "\n",
    "tokens_1 = [Token.BOOLEAN, \n",
    "            Token.ORLY, Token.YARLY, \n",
    "                Token.OTHER_STATEMENT, \n",
    "            Token.NOWAI, \n",
    "                Token.OTHER_STATEMENT, \n",
    "            Token.OIC]\n",
    "\n",
    "tokens_2 = [Token.BOOLEAN, \n",
    "            Token.ORLY, Token.YARLY, \n",
    "                Token.OTHER_STATEMENT,\n",
    "            Token.MEBBE, Token.BOOLEAN,\n",
    "                Token.OTHER_STATEMENT,\n",
    "            Token.NOWAI, \n",
    "                Token.OTHER_STATEMENT, \n",
    "            Token.OIC]\n",
    "\n",
    "tokens_3 = [Token.BOOLEAN, \n",
    "            Token.ORLY, Token.YARLY, \n",
    "                Token.OTHER_STATEMENT,\n",
    "            Token.MEBBE, Token.BOOLEAN,\n",
    "                Token.OTHER_STATEMENT,\n",
    "            Token.NOWAI, \n",
    "                Token.BOOLEAN, \n",
    "                Token.ORLY, Token.YARLY, \n",
    "                    Token.OTHER_STATEMENT, \n",
    "                Token.NOWAI, \n",
    "                    Token.OTHER_STATEMENT,\n",
    "                Token.OIC,\n",
    "            Token.OIC]\n",
    "\n",
    "tokens_4 = [Token.BOOLEAN, \n",
    "            Token.ORLY, Token.YARLY,  \n",
    "            Token.NOWAI, \n",
    "                Token.OTHER_STATEMENT, \n",
    "            Token.OIC]\n",
    "\n",
    "tokens_5 = [Token.BOOLEAN, \n",
    "            Token.ORLY, Token.YARLY, \n",
    "                Token.OTHER_STATEMENT,\n",
    "            Token.MEBBE, Token.BOOLEAN,\n",
    "                Token.OTHER_STATEMENT,\n",
    "            Token.NOWAI, \n",
    "                Token.BOOLEAN, \n",
    "                Token.ORLY, Token.YARLY, \n",
    "                    Token.OTHER_STATEMENT, \n",
    "                Token.NOWAI, \n",
    "                    Token.OTHER_STATEMENT,\n",
    "            Token.OIC]\n",
    "    \n",
    "print(parse_LOLCODE_IF_ELSE(tokens_1))\n",
    "print('----------')\n",
    "#print(parse_LOLCODE_IF_ELSE(tokens_2))\n",
    "#print('----------')\n",
    "#print(parse_LOLCODE_IF_ELSE(tokens_3))\n",
    "#print('----------')\n",
    "#print(parse_LOLCODE_IF_ELSE(tokens_4))\n",
    "#print('----------')\n",
    "#print(parse_LOLCODE_IF_ELSE(tokens_5))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una implementación sencilla e ingenua de un analizador sintáctico del tipo descendente recursivo. \n",
    "\n",
    "Esta estrategia de parseo tiene una gran desventaja. \n",
    "\n",
    "¿Qué derivaciones no se podrían implementar trivialmente con esta estrategia, donde cada no-terminal se representa con una llamada a función?\n",
    "\n",
    "¿Cómo podríamos reorganizar la gramática para manejar estos casos (directo e indirecto)?\n",
    "\n",
    "https://slideplayer.com/slide/2342945/8/images/18/EXAMPLE+2+S+%C2%AE+A+A+%7C+0.+A+%C2%AE+S+S+%7C+1.+Answer.+Considering+the+ordering+S%2C+A%2C+we+get%3A+A+%C2%AE+AAS+%7C+0S+%7C+1..jpg\n",
    "\n",
    "Existen estrategias de análisis gramatical alternas que son más robustas, pero más difíciles de implementar: \n",
    "\n",
    "LL - Descendente predictivo\n",
    "LR - Ascendente\n",
    "\n",
    "No ahondamos en su implementación, pues esto se cubre en la clase de traductores. Sin embargo, es importante conocer sus diferencias y saberlos identificar. \n",
    "\n",
    "\n",
    "Descendente predictivo LL(k)\n",
    "\n",
    "La \"LL\" viene de Left-to-right Leftmost, pues hace el barrido de izquierda a derecha y descendiendo en la primera derivación izquierda que encuentre. \n",
    "\n",
    "La \"k\" es la cantidad de tokens que puede observar hacia adelante para tomar una decisión. En inglés se le llama \"look ahead tokens\" y se almacena en un buffer. \n",
    "\n",
    "A diferencia de un descendente recursivo, no debe haber \"backtracking\". Esto es, utiliza una tabla para codificar la decisión de qué derivación con base en los k tokens que puede ver al futuro. En contraste, un descedente recursivo es exhaustivo y verifica todas las posibles rutas antes de tomar una decisión, puede hacer backtrack si determina que tomó la derivación equivocada. \n",
    "\n",
    "Un descendente recursivo también puede hacerse predictivo. La diferencia es que un LL(k) corre en tiempo lineal, porque usa una tabla para tomar decisiones concretas de derivación. Sin embargo, la gramática debe ser LL(k) también, donde todas las decisiones puedan ser tomadas viendo k tokens hacia adelante. Un descendente recursivo, con o sin predicción, puede procesar gramáticas LL(*), pero en tiempo exponencial. \n",
    "\n",
    "Un LL(k) marca un error cuando no encuentra una decisión en la tabla. Un descedente recursivo marca error cuando llega al final y le quedan tokens. Intentó todas las alternativas y ninguna derivación aceptó el stream de tokens tal cual. \n",
    "\n",
    "La mayoría de los lenguajes optan por analizadores LL(1). Son eficientes y fáciles de implementar. \n",
    "\n",
    "Tanto un descendente recursivo como un predictivo pertenecen a la familia de los top-down. Empezamos de la derivación principal, en la raiz del árbol abstracto de sintaxis, y vamos descendiendo con base en las reglas gramaticales. \n",
    "\n",
    "Con lo que acabamos de aprender, ¿cómo catalogarías el ejemplo en Python de analizador que vimos antes?\n",
    "\n",
    "\n",
    "Ascendente LR(k)\n",
    "\n",
    "Left-to-right, Rightmost derivation in reverse. \n",
    "\n",
    "Son deterministicos, corren en tiempo lineal y no usan predicción o backtracking. Lo hace acumulando tokens, mientras construye sub-árboles de sintaxis, antes de tomar una decisión. Esta estrategia se llama shift-reduce, en un paso shift acumula otro token en el stack, y en reduce, genera una producción gramatical con los tokens acumulados al momento. \n",
    "\n",
    "En vez de seguir una producción como guía en cada token que vamos barriendo, un LR barre tokens hasta encontrar la regla gramatical que más se parece y luego hace el match. Por tanto, pueden manejar algunos casos de recursión izquierda y factores comunes, en función de los k tokens que puedan ver antes de una reducción. \n",
    "\n",
    "Los analizadores LR pertenecen a la familia de bottom-up, pues comienzan en las producciones más particulares, armando sub-árboles poco a poco y combinándolos para llegar a la raíz. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis semántico\n",
    "\n",
    "La estrategia más común es anotar el árbol abstracto de sintaxis y generar una tabla de símbolos. Las anotaciones son etiquetas que ayudan a verificar que los tipos sean correctos, que las variables sean declaradas antes de usarse, que existe una implementación para un encabezado de función y esté asociado correctamente (C++), entre otras verificaciones dependiendo del lenguaje. \n",
    "\n",
    "Por lo general se realiza una vez que el AAS está construído, pero también se pueden embeber algunas reglas durante la etapa de análisis sintáctico. \n",
    "\n",
    "Muchas de las reglas de semántica son expresadas informalmente. No obstante, existe un campo de las ciencias computacionales dedicado al análisis del significado de un lenguaje de programación: semántica formal\n",
    "\n",
    "Las aproximaciones más populares son: \n",
    "\n",
    "Operacional\n",
    "\n",
    "Denotacional\n",
    "\n",
    "Axiomática\n",
    "\n",
    "La teoría de tipos, otro campo de las ciencias computacionales, se adentra en este aspecto semántico de los lenguajes en detalle. \n",
    "\n",
    "Ambas áreas, semántica formal y computacional, así como teoría de tipos, no solamente se enfocan en lenguajes de programación, sino en linguística y matemáticas. \n",
    "\n",
    "Este curso cubre aspectos semánticos básicos, si desean más información, recomiendo las siguientes lecturas: \n",
    "\n",
    "Types and Programming Languages, Benjamin C. Pierce\n",
    "Advanced Topics in Types and Programming Languages, Benjamin C. Pierce\n",
    "Homotopy Type Theory\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
